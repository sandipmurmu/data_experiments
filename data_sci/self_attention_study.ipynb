{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self attention solves a major issue in RNN which faces unable to process large/long text/docs. RNN also suffers from vanishinng gradients and gradient explosions, often needs large training step to reach local/global minima\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
