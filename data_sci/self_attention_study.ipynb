{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Self attention solves a major issue in RNN which faces unable to process large/long text/docs. RNN also suffers from vanishinng gradients and gradient explosions, often needs large training step to reach local/global minima\n",
    "Ref: https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\n",
    "Self attention provides an attention mechanism to provide access to all sequence elements at each time step. It enables the model to weigh the importance/weights of elements in a sequence and adjust them for generating the output\n",
    "\n",
    "Various variants: scaled dot product attention is popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'account': 0, 'and': 1, 'are': 2, 'be': 3, 'because': 4, 'can': 5, 'changes': 6, 'does': 7, 'economy': 8, 'for': 9, 'future': 10, 'guide': 11, 'history': 12, 'it': 13, 'market': 14, 'misleading': 15, 'not': 16, 'of': 17, 'relevant': 18, 'stock': 19, 'structural': 20, 'that': 21, 'the': 23, 'to': 25, \"today's\": 26, 'world': 27}\n"
     ]
    }
   ],
   "source": [
    "# creating a sentence embeddeing\n",
    "sentence = \"history can be misleading guide to the future of the economy and stock market because it does not account for structural changes that are relevant to today's world\"\n",
    "#sentence = 'Life is short, eat dessert first'\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(\",\",\"\").split()))}\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "\n",
    "sentence_int = torch.tensor([dc[s] for s in sentence.replace(\",\",\"\").split()])\n",
    "#print(sentence_int)\n",
    "print(sentence_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 16])\n"
     ]
    }
   ],
   "source": [
    "# use an embedding to encode the numerical representation of the sentence (sentence_int)\n",
    "torch.manual_seed(123)\n",
    "# contains 28 words or more as 50000. lets assume each word is represented by 16 dimensional vector\n",
    "embedding = torch.nn.Embedding(50000, 16)\n",
    "embedded_sentence = embedding(sentence_int).detach()\n",
    "print(embedded_sentence.shape)\n",
    "#print(embedded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self attention use 3 weights matrices, wq, wk, wv. These weights are adjusted during training. The matrices project the inputs into - query, key and value, components of sequence\n",
    "Each of the sequence is obtained by dot product sequence and respective weights\n",
    "\n",
    "Query and key vector should be of same dimension, as need to compute the dot product between them (i.e., d_q = d_k)\n",
    "Value vector is arbitrary\n",
    "\n",
    "Query, Key and Value - are 3 Linear layers. \n",
    "Query = the text which is searched.\n",
    "Key = title/key of the artical or video.\n",
    "Value = the content inside the artifact. \n",
    "\n",
    "The 3 matrices can be considered as a #### single attention #### head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 24])\n"
     ]
    }
   ],
   "source": [
    "d = embedded_sentence.shape[1]\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "# initializa the weight matrices\n",
    "wq = torch.nn.Parameter(torch.rand(d, d_q))\n",
    "wk = torch.nn.Parameter(torch.rand(d, d_k))\n",
    "wv = torch.nn.Parameter(torch.rand(d, d_v))\n",
    "\n",
    "print(wq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# compute (matmul or @ ) the unnormalized attention weights \n",
    "x = embedded_sentence\n",
    "Q = x @ wq\n",
    "K = x @ wk\n",
    "V = x @ wv\n",
    "\n",
    "#print(Q.shape)\n",
    "#print(K.shape)\n",
    "#print(V.shape)\n",
    "# similarity cosine\n",
    "omega = Q @ K.T\n",
    "print(omega.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      " the input dimension is 16, but the output dimension is 28\n"
     ]
    }
   ],
   "source": [
    "attention_score = omega / math.sqrt(d_k)\n",
    "attention_weights = F.softmax(attention_score, dim=1)\n",
    "context_vector = attention_weights @ V\n",
    "print(context_vector.shape)\n",
    "#print(context_vector)\n",
    "print(\" the input dimension is {}, but the output dimension is {}\".format(embedded_sentence.shape[1], context_vector.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
